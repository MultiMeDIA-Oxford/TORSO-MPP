{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImageSegmentor","provenance":[],"authorship_tag":"ABX9TyO2VZ70GZ90KsUAm3Au3hw1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kjxMd2EinF3A","executionInfo":{"status":"ok","timestamp":1608051454993,"user_tz":0,"elapsed":4204,"user":{"displayName":"Hannah Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCuuU1Qe2V2bPKvl2h8AKtPYURxd5sWn-zAZZ_=s64","userId":"15746458071079357861"}}},"source":["import os\r\n","import torch\r\n","import torch.nn as nn\r\n","import torchvision.transforms.functional as TF\r\n","import torch.nn.functional as F\r\n","from torchvision import datasets, transforms\r\n","from torch.utils.data import Dataset, DataLoader\r\n","import PIL\r\n","from PIL import Image "],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RJrb-DvSi4cr","executionInfo":{"status":"ok","timestamp":1608051476525,"user_tz":0,"elapsed":20670,"user":{"displayName":"Hannah Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCuuU1Qe2V2bPKvl2h8AKtPYURxd5sWn-zAZZ_=s64","userId":"15746458071079357861"}},"outputId":"1e2c480b-f0e8-4b0b-f924-9cbc9758d605"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_JWn9Vvurssp","executionInfo":{"status":"ok","timestamp":1608051479449,"user_tz":0,"elapsed":688,"user":{"displayName":"Hannah Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCuuU1Qe2V2bPKvl2h8AKtPYURxd5sWn-zAZZ_=s64","userId":"15746458071079357861"}}},"source":["torch.set_default_tensor_type('torch.cuda.FloatTensor')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7zxxgJXqo2x","executionInfo":{"status":"ok","timestamp":1608051481715,"user_tz":0,"elapsed":558,"user":{"displayName":"Hannah Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCuuU1Qe2V2bPKvl2h8AKtPYURxd5sWn-zAZZ_=s64","userId":"15746458071079357861"}}},"source":["class ImageDataset(Dataset):\r\n","    '''\r\n","    Creates a dataset of images from filepaths\r\n","    No augmentation, just necessary resizing\r\n","    Returns the image name and the resized image as a tensor\r\n","    '''\r\n","\r\n","    def __init__(self, image_paths):\r\n","        self.image_paths = image_paths\r\n","\r\n","    def transform(self, image):\r\n","        # Resize\r\n","        resize = transforms.Resize(size=(128, 128))\r\n","        image = resize(image)\r\n","                  \r\n","        # Transform to tensor\r\n","        image = TF.to_tensor(image).cuda()\r\n","        return image\r\n","\r\n","    def __getitem__(self, index):\r\n","        image = Image.open(self.image_paths[index])\r\n","        image = self.transform(image)\r\n","        img_name = self.image_paths[index].split('/')[-1]\r\n","        return img_name, image\r\n","\r\n","    def __len__(self):\r\n","        return len(self.image_paths)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DKWwDEoq0y1","executionInfo":{"status":"ok","timestamp":1608051486724,"user_tz":0,"elapsed":665,"user":{"displayName":"Hannah Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCuuU1Qe2V2bPKvl2h8AKtPYURxd5sWn-zAZZ_=s64","userId":"15746458071079357861"}}},"source":["class UNet(nn.Module):\r\n","    def __init__(self, n_channels, n_classes, bilinear=True):\r\n","        super(UNet, self).__init__()\r\n","        self.n_channels = n_channels\r\n","        self.n_classes = n_classes\r\n","\r\n","        self.bilinear = bilinear #if UNet uses bilinear upsampling\r\n","        \r\n","        self.inc = DoubleConv(n_channels, 64)\r\n","        self.down1 = Down(64, 128)\r\n","        self.down2 = Down(128, 256)\r\n","        self.down3 = Down(256, 512)\r\n","        factor = 2 if bilinear else 1\r\n","        self.down4 = Down(512, 1024 // factor)\r\n","        self.up1 = Up(1024, 512 // factor, bilinear)\r\n","        self.up2 = Up(512, 256 // factor, bilinear)\r\n","        self.up3 = Up(256, 128 // factor, bilinear)\r\n","        self.up4 = Up(128, 64, bilinear)\r\n","        self.outc = OutConv(64, n_classes)\r\n","        \r\n","    def forward(self, x):\r\n","        x1 = self.inc(x)\r\n","        x2 = self.down1(x1)\r\n","        x3 = self.down2(x2)\r\n","        x4 = self.down3(x3)\r\n","        x5 = self.down4(x4)\r\n","        x = self.up1(x5, x4)\r\n","        x = self.up2(x, x3)\r\n","        x = self.up3(x, x2)\r\n","        x = self.up4(x, x1)\r\n","        # Added sigmoid activation layer to help binarise output\r\n","        logits = F.sigmoid(self.outc(x))\r\n","        return logits\r\n","\r\n","\r\n","class DoubleConv(nn.Module):\r\n","    \"\"\"(Convolution -> Batch normalization -> ReLU activation) * 2\"\"\"\r\n","\r\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\r\n","        super().__init__()\r\n","        if not mid_channels:\r\n","            mid_channels = int(out_channels)\r\n","        self.double_conv = nn.Sequential(\r\n","            nn.Conv2d(int(in_channels), mid_channels, kernel_size=3, padding=1), #initial kernel 3\r\n","            nn.BatchNorm2d(mid_channels),\r\n","            nn.ReLU(inplace=True),\r\n","            nn.Conv2d(mid_channels, int(out_channels), kernel_size=3, padding=1), #initial kernel 3\r\n","            nn.BatchNorm2d(int(out_channels)),\r\n","            nn.ReLU(inplace=True)\r\n","        )\r\n","\r\n","    def forward(self, x):\r\n","        return self.double_conv(x)\r\n","\r\n","\r\n","class Down(nn.Module):\r\n","    \"\"\"Downscaling with maxpool then double conv\"\"\"\r\n","\r\n","    def __init__(self, in_channels, out_channels):\r\n","        super().__init__()\r\n","        self.maxpool_conv = nn.Sequential(\r\n","            nn.MaxPool2d(2),\r\n","            DoubleConv(int(in_channels), int(out_channels))\r\n","        )\r\n","\r\n","    def forward(self, x):\r\n","        return self.maxpool_conv(x)\r\n","\r\n","\r\n","class Up(nn.Module):\r\n","    \"\"\"Upscaling then double conv\"\"\"\r\n","\r\n","    def __init__(self, in_channels, out_channels, bilinear=True):\r\n","        super().__init__()\r\n","\r\n","        # if bilinear, use the normal convolutions to reduce the number of channels\r\n","        if bilinear:\r\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\r\n","            self.conv = DoubleConv(int(in_channels), int(out_channels), int(in_channels) // 2)\r\n","        else:\r\n","            self.up = nn.ConvTranspose2d(int(in_channels), int(in_channels) // 2, kernel_size=2, stride=2)\r\n","            self.conv = DoubleConv(int(in_channels), int(out_channels))\r\n","\r\n","\r\n","    def forward(self, x1, x2):\r\n","        x1 = self.up(x1)\r\n","        # input is CHW\r\n","        diffY = x2.size()[2] - x1.size()[2]\r\n","        diffX = x2.size()[3] - x1.size()[3]\r\n","\r\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\r\n","                        diffY // 2, diffY - diffY // 2])\r\n","        x = torch.cat([x2, x1], dim=1)\r\n","        return self.conv(x)\r\n","\r\n","\r\n","class OutConv(nn.Module):\r\n","    def __init__(self, in_channels, out_channels):\r\n","        super(OutConv, self).__init__()\r\n","        self.conv = nn.Conv2d(int(in_channels), int(out_channels), kernel_size=1)\r\n","\r\n","    def forward(self, x):\r\n","        return self.conv(x)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOWE-gLfjazo","executionInfo":{"status":"ok","timestamp":1608051542749,"user_tz":0,"elapsed":48712,"user":{"displayName":"Hannah Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCuuU1Qe2V2bPKvl2h8AKtPYURxd5sWn-zAZZ_=s64","userId":"15746458071079357861"}},"outputId":"2689333a-de4f-40b1-f97a-ca3826c963da"},"source":["#define directories input images are in and output segmented images are to be saved in\r\n","#****change here for input and output dirs****\r\n","image_dir = '/content/gdrive/MyDrive/GrauRotation/training-data/Hannah-contours-fullpats14/1000037/complete-images'\r\n","segment_dir = '/content/gdrive/MyDrive/GrauRotation/testing-contours/1000037-seg-test'\r\n","if not os.path.isdir(segment_dir):\r\n","    os.mkdir(segment_dir)\r\n","\r\n","#define and load model\r\n","#****change here for model path****\r\n","model_path = '/content/gdrive/MyDrive/GrauRotation/models/N15-CV/N15_cycle_4.pt'\r\n","[model, x_valid_paths, train_losses, valid_losses]  = torch.load(model_path)\r\n","\r\n","#images into data loader\r\n","image_filepaths = sorted([f.path for f in os.scandir(image_dir) if f.is_file()])\r\n","test_dataset = ImageDataset(image_filepaths)\r\n","test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\r\n","\r\n","#iterate over test loader making image segmentations and binarising them\r\n","with torch.no_grad():\r\n","    for b, (img_names, images) in enumerate(test_loader):\r\n","        y_results = model(images)\r\n","        y_results[y_results < 0.5] = 0\r\n","        y_results[y_results > 0.5] = 1\r\n","\r\n","        #converts segmentations into PIL images and saves them\r\n","        for i, result in enumerate(y_results):\r\n","          name = img_names[i]\r\n","          save_path = os.path.join(segment_dir, name)\r\n","          img = transforms.ToPILImage()(result[0].cpu())\r\n","          img.save(save_path)\r\n","        "],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Pzq-8j010Ph9"},"source":[""],"execution_count":null,"outputs":[]}]}